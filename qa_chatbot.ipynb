{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python==3.10.13  \n",
    "langchain==0.1.6  \n",
    "langchain-community==0.0.19  \n",
    "openai==1.12.0  \n",
    "tiktoken==0.6.0  \n",
    "gradio==3.48.0  \n",
    "chromadb==0.4.22  \n",
    "\n",
    "reference:\n",
    "1. https://www.youtube.com/watch?v=eqRMeCrcelM\n",
    "2. https://www.youtube.com/watch?v=iGZ0cV-SRLI&t=1424s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.indexes.vectorstore import VectorstoreIndexCreator, VectorStoreIndexWrapper\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "from langchain.memory import ConversationBufferMemory, ConversationBufferWindowMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the raw file and parse it into proper format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'raw_doc/knowledge.txt'\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['How do I change my address in the Kora app?',\n",
       " 'Can international students use Kora?',\n",
       " 'How Do I Get in Touch with Kora?',\n",
       " 'App not working? Try closing it and downloading the most recent version.',\n",
       " 'Is Kora available for Android?',\n",
       " 'What is credit and how does it work?']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword = \"Question\"\n",
    "questions = [line[len(keyword):].strip(\"\\n\") for line in content.split('#') if keyword in line]\n",
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = \"Answer\"\n",
    "answers = [line[len(keyword):].strip(\"\\n\") for line in content.split('#') if keyword in line]\n",
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(question, answer, file_path):\n",
    "\n",
    "    text = f\"\"\"\n",
    "Q: {question}\n",
    "A: {answer}\n",
    "\"\"\".strip()\n",
    "    \n",
    "    with open(file_path, 'w') as text_file:\n",
    "        text_file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(questions)):\n",
    "\n",
    "    export_file = f'parsed_doc/question_{i}.txt'\n",
    "\n",
    "    write_file(\n",
    "        question=questions[i], \n",
    "        answer=answers[i], \n",
    "        file_path=export_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create vectorDB from the raw Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "loader = DirectoryLoader(\"./parsed_doc/\", glob=\"**/*txt\")\n",
    "documents = loader.load()\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Q: How do I change my address in the Kora app?\\n\\nA: If you entered your address incorrectly or need to update it to a new address, we can help.\\n\\nIn your Kora app, go to “Settings”, click on “Profile”, you should be able to change the address by tapping on “Edit”', metadata={'source': 'parsed_doc\\\\question_0.txt'})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Chroma.from_documents(documents=texts, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.similarity_search('international student')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. export and reload db\n",
    "say we dont want to re-create vectorDB every single time to save time and cost\n",
    "we could export the vectorDB and load it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_persist_path = \"./vector_store\"\n",
    "\n",
    "def get_index_path(index_name):\n",
    "    return os.path.join(local_persist_path, index_name)\n",
    "\n",
    "def load_and_save_to_index(loader, index_name):\n",
    "    \n",
    "    # by default, VectorstoreIndexCreator uses openAI API\n",
    "    index = VectorstoreIndexCreator(\n",
    "        vectorstore_kwargs={'persist_directory':get_index_path(index_name)}\n",
    "        ).from_loaders([loader])\n",
    "\n",
    "    # save the vectorDB to avoid regenerating vectors next time\n",
    "    index.vectorstore.persist()\n",
    "\n",
    "# load_and_save_to_index(loader=loader, index_name='test_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the exported vectorDB\n",
    "def load_index(index_name):\n",
    "    index_path = get_index_path(index_name)\n",
    "    # you need to use the same embedding API as in VectorstoreIndexCreators\n",
    "    embedding = OpenAIEmbeddings()\n",
    "    vectordb = Chroma(\n",
    "        persist_directory=index_path,\n",
    "        embedding_function=embedding\n",
    "    )\n",
    "    return vectordb\n",
    "\n",
    "test_db = load_index('test_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_db.similarity_search('international student')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Conversational Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "### Instruction: You are a customer support agent at Kora that is talking to a customer. Use only the chat history and the following information\n",
    "{context}\n",
    "to answer in a helpful and precise manner to the question. \n",
    "If you do not know the answer - say that you do not know and ask the customer to fill out the form at the {link}.\n",
    "If the customer thinks your answer not helpful - say sorry and ask the customer to fill out the form at the {link}.\n",
    "If the customer says bye - say good bye and ask the customer to give you a rating\n",
    "Keep your replies short, compassionate and informative.\n",
    "{chat_history}\n",
    "### Input: {question}\n",
    "### Response:\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=['context', 'question', 'chat_history'],\n",
    "    partial_variables={'link': 'link hidden for privacy. replace with your own link'},\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only look for recent 20 chat history in memory\n",
    "memory = ConversationBufferWindowMemory(\n",
    "    memory_key='chat_history',\n",
    "    human_prefix='### Input',\n",
    "    ai_prefix=\"### Response\",\n",
    "    input_key=\"question\",\n",
    "    output_key=\"output_text\",\n",
    "    return_messages=False,\n",
    "    k=20\n",
    ")\n",
    "\n",
    "# only look for all chat history in memory\n",
    "# memory = ConversationBufferMemory(\n",
    "#     memory_key='chat_history',\n",
    "#     human_prefix='### Input',\n",
    "#     ai_prefix=\"### Response\",\n",
    "#     input_key=\"question\",\n",
    "#     output_key=\"output_text\",\n",
    "#     return_messages=False,\n",
    "# )\n",
    "\n",
    "chain = load_qa_chain(\n",
    "    llm=llm,\n",
    "    chain_type='stuff',\n",
    "    prompt=prompt,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"how to use Kora website\"\n",
    "docs = db.similarity_search(question)\n",
    "answer = chain.run({\n",
    "    \"input_documents\": docs, \n",
    "    \"question\": question\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! To use the Kora website, simply visit our homepage at www.kora.com. From there, you can explore our products and services, learn more about what we offer, and even apply for KoraCash or KoraDrive. If you have any specific questions or need assistance navigating the website, feel free to ask!'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(\n",
    "    memory_key='chat_history',\n",
    "    human_prefix='### Input',\n",
    "    ai_prefix=\"### Response\",\n",
    "    input_key=\"question\",\n",
    "    output_key=\"output_text\",\n",
    "    return_messages=False,\n",
    "    k=20\n",
    ")\n",
    "\n",
    "chain = load_qa_chain(\n",
    "    llm=llm,\n",
    "    chain_type='stuff',\n",
    "    prompt=prompt,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot()\n",
    "    msg = gr.components.Textbox()\n",
    "    clear = gr.ClearButton([msg, chatbot])\n",
    "\n",
    "    def respond(message, chat_history):\n",
    "\n",
    "        docs = db.similarity_search(message)\n",
    "        bot_message = chain.run({\n",
    "            \"input_documents\": docs, \n",
    "            \"question\": message\n",
    "        })\n",
    "        print(bot_message)\n",
    "        chat_history.append((message, bot_message))\n",
    "        return \"\", chat_history\n",
    "    \n",
    "    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
    "\n",
    "demo.launch(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
